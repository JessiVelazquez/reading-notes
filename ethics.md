# Ethics in the Workplace

Article: [The Code I'm Still Ashamed of](https://www.freecodecamp.org/news/the-code-im-still-ashamed-of-e4c021dff55e/)

This article was about a situation where the author was asked to code an online quiz for teenage girls to take in order to recommend them a prescription drug based on their answers - the catch was that any answers they gave all led to the same recommendation - the drug the company was promoting. This is not illegal, but clearly deceptive. The weight of this is that the drug had side effects including depression and suicidal thoughts. Eventually it came out that a girl had killed herself after getting on that drug through the website.

I have mixed feelings here. There are so many variables that go into why this individual reached the point of suicide. Obviously, the drug is a major one. However, there are a lot of drugs out there that can have side effects like this, and that fact alone does not make the drug a universally bad choice. This is a case where information needs to be presented to the users to then make their own choice. Of course, the online quiz appears to have been devoid of any such warnings. But, there should have also been other checks in place to notify the individual about these side effects, such as the pharmacist, her and/or her parents' own research, etc.

It is also entirely possible that for countless other teenage girls, this drug helped them in a positive way.

I definitely do not think that fun, cute little "quizes" like that are at all appropriate for something as serious as prescription drugs. Anything that is profit-focused and comes from non-doctors yet poses as medical advice to youth is SKETCHY in all caps.

That being said, I don't see the developer here as playing a direct role in the suicide. Take the scenario, for example - if the quiz was entirely legitimate and actually DID recommend different drugs based on the questions asked. This outcome still could have easily happened. 

So - I don't think that this quiz was ethical, but I also don't think the author should feel responsible for the death. 

The lesson I have learned reading this is that as developers, we are the "how" in the process of information getting to people, and unfortunately that plays just as much of a role as the "what" and "why" parts of the process. We need to be cognizant of that and understand that if we foresee major problems with code we are asked to write, to stop and consider if this is something to take stand against. 

But, in this case I don't think you can draw a direct line from the unethical code to the death, mainly because even if the quiz did not exist, or if it was not rigged, this girl or someone else still likely could have ended up at the point of suicide due to that drug. 

# Ethics in Technology

Article: [The Cybersecurity of Self-Driving Cars](https://phys.org/news/2017-02-cybersecurity-self-driving-cars.html)

This article is about the risk of cyber terrorist/criminal hack attacks on the software of self-driving vehicles. Any self driving vehicle will be a comples software application that is connected to the cloud, and therefore will be massively susceptible to bugs and to attacks via the internet. In my opinion, this is outright unsafe and is a complete dealbreaker for self-driving car. Sorry. Maybe at some point in the future we will have systems that ACTUALLY negate the possibility of these failures, but at the time being with the way that the connectivity of web and cloud infrastructure work, it is not good enough. 

I see this issue as a lack of customer focus. I often don't understand why we as humans are so blindly driven to keep abstracting and automating things till kingdom come. The answer is that the "need" to keep automating things here is not coming with the customer's best interest in mind, it is coming from a team of developers selfishly wanting to create the next big thing for their own wallets and their own ego. It feels like someone designing and then forcing you to use a tool you don't need just because "it is cool". When in reality it is just adding noise to the system.

Why do we need self driving cars? Well, because there are so many of us. We need to automate the travel grid to make it more efficient. But why do we need that? Maybe the answer here is to use self driving systems to move goods around the globe - food, resources, but not humans. At least not now. I don't care how "cool" it is.
